{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H97aLfuqF7jG"
      },
      "outputs": [],
      "source": [
        "# Install library tambahan jika diperlukan\n",
        "!pip install scikit-learn pandas matplotlib numpy dask\n",
        "\n",
        "# Import library\n",
        "import dask.dataframe as dd\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import silhouette_score, davies_bouldin_score, calinski_harabasz_score\n",
        "\n",
        "# Upload file CSV\n",
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Membaca data dari file CSV menggunakan Dask\n",
        "file_name = list(uploaded.keys())[0]\n",
        "data = dd.read_csv(file_name)"
      ],
      "metadata": {
        "id": "mRofUXVRIpck"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Target kolom yang akan digunakan\n",
        "target_columns = ['TSS', 'pH', 'EC', 'TDS', 'CHLA']\n",
        "data = data[target_columns]\n",
        "\n",
        "# Mengetahui jumlah nilai null per kolom\n",
        "null_counts = data.isna().sum().compute()\n",
        "print(\"Jumlah nilai null awal pada setiap kolom:\")\n",
        "print(null_counts)\n",
        "print(\"-\" * 50)\n",
        "\n",
        "# Mengisi nilai NaN dengan median (menggunakan Dask)\n",
        "data = data.fillna(data.median().compute())\n",
        "\n",
        "# Memastikan tidak ada nilai null setelah pengisian\n",
        "null_counts_after = data.isna().sum().compute()\n",
        "print(\"Jumlah nilai null setelah pengisian:\")\n",
        "print(null_counts_after)\n",
        "print(\"-\" * 50)\n",
        "\n",
        "# Mengonversi ke Pandas untuk kompatibilitas dengan Scikit-learn\n",
        "data = data.compute()\n",
        "\n",
        "# Standarisasi data\n",
        "scaler = StandardScaler()\n",
        "scaled_data = scaler.fit_transform(data)\n",
        "\n",
        "# PCA untuk menurunkan dimensi menjadi 2 komponen\n",
        "pca = PCA(n_components=2)\n",
        "pca_result = pca.fit_transform(scaled_data)\n",
        "data[['PCA1', 'PCA2']] = pca_result  # Menyimpan kedua komponen"
      ],
      "metadata": {
        "id": "oByQRCeBIrhL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data[['PCA1', 'PCA2']].reset_index(drop=True).head(50)"
      ],
      "metadata": {
        "id": "WKlwF9OkR32Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scaled_df = pd.DataFrame(scaled_data, columns=target_columns)\n",
        "print(scaled_df.head())"
      ],
      "metadata": {
        "id": "y5MZLIhy-Rbc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**EVALUASI HASIL KLASTERING**"
      ],
      "metadata": {
        "id": "we1w9KVap85G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import silhouette_score, davies_bouldin_score, calinski_harabasz_score\n",
        "from sklearn.metrics import pairwise_distances\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "qveM-TnjVQKK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fungsi untuk menghitung Gap Statistic\n",
        "def gap_statistic(X, n_refs=5, max_clusters=5):\n",
        "    from sklearn.cluster import KMeans\n",
        "    import numpy as np\n",
        "\n",
        "    gaps = []\n",
        "    for k in range(1, max_clusters + 1):\n",
        "        ref_disps = []\n",
        "        for _ in range(n_refs):\n",
        "            random_reference = np.random.uniform(X.min(axis=0), X.max(axis=0), size=X.shape)\n",
        "            km = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
        "            km.fit(random_reference)\n",
        "            ref_disps.append(km.inertia_)\n",
        "\n",
        "        km = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
        "        km.fit(X)\n",
        "        orig_disp = km.inertia_\n",
        "\n",
        "        gap = np.log(np.mean(ref_disps)) - np.log(orig_disp)\n",
        "        gaps.append(gap)\n",
        "\n",
        "    return gaps\n",
        "\n",
        "# Hitung Gap Statistic\n",
        "gaps = gap_statistic(data[['PCA1', 'PCA2']].values, n_refs=5, max_clusters=5)\n",
        "\n",
        "# Evaluasi KMeans dengan berbagai metrik\n",
        "for n_clusters in [2, 3, 4, 5]:\n",
        "    kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)\n",
        "    data['Cluster'] = kmeans.fit_predict(data[['PCA1', 'PCA2']])\n",
        "\n",
        "    silhouette_avg = silhouette_score(data[['PCA1', 'PCA2']], data['Cluster'])\n",
        "    dbi = davies_bouldin_score(data[['PCA1', 'PCA2']], data['Cluster'])\n",
        "    calinski_harabasz = calinski_harabasz_score(data[['PCA1', 'PCA2']], data['Cluster'])\n",
        "    wss = kmeans.inertia_\n",
        "    gap = gaps[n_clusters-1]\n",
        "\n",
        "    print(f\"Evaluasi untuk {n_clusters} Klaster:\")\n",
        "    print(f\"  Davies-Bouldin Index: {dbi:.5f}\")\n",
        "    print(f\"  Silhouette Score: {silhouette_avg:.5f}\")\n",
        "    print(f\"  Calinski-Harabasz Index: {calinski_harabasz:.5f}\")\n",
        "    print(f\"  Within-Cluster Sum of Squares (WSS / Cohesion): {wss:.5f}\")\n",
        "    print(f\"  Gap Statistic: {gap:.5f}\")\n",
        "    print(\"-\" * 50)\n"
      ],
      "metadata": {
        "id": "Gyi3wxxfm6J6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import silhouette_score, davies_bouldin_score, calinski_harabasz_score\n",
        "from sklearn.metrics import pairwise_distances\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "for n_clusters in [2, 3, 4, 5]:\n",
        "    kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
        "    data['Cluster'] = kmeans.fit_predict(data[['PCA1', 'PCA2']])\n",
        "\n",
        "    # Menampilkan jumlah data dalam setiap klaster\n",
        "    cluster_counts = data['Cluster'].value_counts().sort_index()\n",
        "    print(f\"\\nJumlah data per klaster untuk {n_clusters} Klaster:\")\n",
        "    for cluster, count in cluster_counts.items():\n",
        "        print(f\"  Cluster {cluster + 1}: {count}\")\n",
        "\n",
        "    print(\"-\" * 50)\n"
      ],
      "metadata": {
        "id": "WoEWCq4msH77"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Melihat eigenvalues dan eigenvectors\n",
        "eigenvectors = pca.components_\n",
        "\n",
        "# Explained variance ratio dan eigenvalues\n",
        "explained_variance_ratio = pca.explained_variance_ratio_\n",
        "eigenvalues = pca.explained_variance_\n",
        "\n",
        "print(\"Explained Variance Ratio (Proporsi Variansi yang Dijelaskan) untuk Setiap Komponen:\")\n",
        "print(explained_variance_ratio)\n",
        "\n",
        "print(\"\\nEigenvalues (Nilai Eigen):\")\n",
        "print(eigenvalues)\n",
        "\n",
        "print(\"\\nEigenvectors:\")\n",
        "print(eigenvectors)"
      ],
      "metadata": {
        "id": "WSDAcuGasBwr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "kmeans = KMeans(n_clusters=5, random_state=42)\n",
        "data['Cluster'] = kmeans.fit_predict(data[['PCA1', 'PCA2']])\n",
        "\n",
        "# Gabungkan hasil klaster dengan data asli\n",
        "cluster_summary = data.groupby('Cluster')[['TSS', 'pH', 'EC', 'TDS', 'CHLA']].mean()\n",
        "print(cluster_summary)"
      ],
      "metadata": {
        "id": "lcpqhG5DVFOs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Klasterisasi menggunakan KMeans dengan 5 klaster\n",
        "kmeans = KMeans(n_clusters=5, random_state=42)\n",
        "kmeans.fit(scaled_data)\n",
        "data['Cluster'] = kmeans.labels_\n",
        "\n",
        "# Cek hasil label klaster\n",
        "print(\"Hasil label klaster KMeans:\")\n",
        "print(kmeans.labels_)\n",
        "\n",
        "# Step 3: Hitung rata-rata tiap variabel per klaster\n",
        "cluster_means = pd.DataFrame(scaled_data, columns=target_columns)\n",
        "cluster_means['Cluster'] = kmeans.labels_\n",
        "cluster_means = cluster_means.groupby('Cluster').mean()\n",
        "\n",
        "print(\"Rata-rata tiap variabel setelah standarisasi per klaster:\")\n",
        "print(cluster_means)\n",
        "\n",
        "# Step 4: Membuat radar plot per klaster\n",
        "def create_spider_plot_per_cluster(cluster_means):\n",
        "    labels = cluster_means.columns.tolist()\n",
        "    num_vars = len(labels)\n",
        "    angles = np.linspace(0, 2 * np.pi, num_vars, endpoint=False).tolist()\n",
        "    angles += angles[:1]\n",
        "\n",
        "    # Warna untuk 5 klaster, urut sesuai label 0,1,2,3,4\n",
        "    colors = ['#1f77b4', 'orange', 'green', 'red', 'purple']\n",
        "\n",
        "    for cluster in sorted(cluster_means.index):  # urutkan label klaster\n",
        "        values = cluster_means.loc[cluster].values.flatten().tolist()\n",
        "        values += values[:1]\n",
        "\n",
        "        fig, ax = plt.subplots(figsize=(7, 7), subplot_kw=dict(polar=True))\n",
        "        ax.plot(angles, values, marker='o', linewidth=2, color=colors[cluster])\n",
        "        ax.fill(angles, values, alpha=0.25, color=colors[cluster])\n",
        "\n",
        "        ax.set_xticks(angles[:-1])\n",
        "        ax.set_xticklabels(labels, fontsize=10, rotation=30, ha=\"right\")\n",
        "\n",
        "        ax.set_title(f'Radar Plot Klaster {cluster}', size=14, y=1.08)\n",
        "        ax.set_yticklabels([])\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "# Panggil fungsi untuk buat radar per klaster\n",
        "create_spider_plot_per_cluster(cluster_means)\n"
      ],
      "metadata": {
        "id": "IS-uY245EFWO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Klasterisasi menggunakan KMeans dengan 5 klaster\n",
        "kmeans = KMeans(n_clusters=5, random_state=42)\n",
        "kmeans.fit(scaled_data)\n",
        "data['Cluster'] = kmeans.labels_\n",
        "\n",
        "# Step 3: Hitung rata-rata tiap variabel per klaster\n",
        "cluster_means = pd.DataFrame(scaled_data, columns=target_columns)\n",
        "cluster_means['Cluster'] = kmeans.labels_\n",
        "cluster_means = cluster_means.groupby('Cluster').mean()\n",
        "\n",
        "print(kmeans.labels_)\n",
        "\n",
        "print(\"Rata-rata tiap variabel setelah standarisasi per klaster:\")\n",
        "print(cluster_means)\n",
        "\n",
        "# Step 4: Membuat radar plot per klaster\n",
        "def create_spider_plot_per_cluster(cluster_means):\n",
        "    labels = cluster_means.columns.tolist()\n",
        "    num_vars = len(labels)\n",
        "    angles = np.linspace(0, 2 * np.pi, num_vars, endpoint=False).tolist()\n",
        "    angles += angles[:1]\n",
        "\n",
        "    # Warna untuk 5 klaster\n",
        "    colors = ['#1f77b4', 'orange', 'green', 'red', 'purple']\n",
        "\n",
        "    for cluster in cluster_means.index:\n",
        "        values = cluster_means.loc[cluster].values.flatten().tolist()\n",
        "        values += values[:1]\n",
        "\n",
        "        fig, ax = plt.subplots(figsize=(7, 7), subplot_kw=dict(polar=True))\n",
        "        ax.plot(angles, values, marker='o', linewidth=2, color=colors[cluster])\n",
        "        ax.fill(angles, values, alpha=0.25, color=colors[cluster])\n",
        "\n",
        "        ax.set_xticks(angles[:-1])\n",
        "        ax.set_xticklabels(labels, fontsize=10, rotation=30, ha=\"right\")\n",
        "\n",
        "        ax.set_title(f'Radar Plot Klaster {cluster+1}', size=14, y=1.08)\n",
        "        ax.set_yticklabels([])\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "# Panggil fungsi untuk buat radar per klaster\n",
        "create_spider_plot_per_cluster(cluster_means)\n"
      ],
      "metadata": {
        "id": "XcQEQXEJzfe8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_combined_spider_plot(cluster_means):\n",
        "    labels = cluster_means.columns.tolist()\n",
        "    num_vars = len(labels)\n",
        "    angles = np.linspace(0, 2 * np.pi, num_vars, endpoint=False).tolist()\n",
        "    angles += angles[:1]\n",
        "\n",
        "    # Warna untuk 5 klaster\n",
        "    colors = ['#1f77b4', 'orange', 'green', 'red', 'purple']\n",
        "\n",
        "    # Buat figure tunggal\n",
        "    fig, ax = plt.subplots(figsize=(8, 8), subplot_kw=dict(polar=True))\n",
        "\n",
        "    for cluster in cluster_means.index:\n",
        "        values = cluster_means.loc[cluster].values.flatten().tolist()\n",
        "        values += values[:1]\n",
        "\n",
        "        ax.plot(angles, values, marker='o', linewidth=2, label=f'Klaster {cluster+1}', color=colors[cluster])\n",
        "        ax.fill(angles, values, alpha=0.15, color=colors[cluster])\n",
        "\n",
        "    ax.set_xticks(angles[:-1])\n",
        "    ax.set_xticklabels(labels, fontsize=10, rotation=30, ha=\"right\")\n",
        "\n",
        "    ax.set_title('Radar Plot Tiap Klaster', size=16, y=1.1)\n",
        "    ax.set_yticklabels([])\n",
        "\n",
        "    ax.legend(loc='upper right', bbox_to_anchor=(1.3, 1.1))\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Panggil fungsi\n",
        "create_combined_spider_plot(cluster_means)\n"
      ],
      "metadata": {
        "id": "n7Uo6ly42EZN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**DOWNLOAD FILE**"
      ],
      "metadata": {
        "id": "Gk4VO3fQqHjI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Menambahkan kolom 'Cluster_X' untuk setiap jumlah klaster\n",
        "for n_clusters in [2, 3, 4, 5]:\n",
        "    kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
        "    data[f'Cluster_{n_clusters}'] = kmeans.fit_predict(data[['PCA1', 'PCA2']])\n",
        "\n",
        "# Mengekspor data ke file Excel\n",
        "output_file = 'hasil_klasterisasi_kmeans_pca_revisi1_1.xlsx'\n",
        "data.to_excel(output_file, index=False)\n",
        "\n",
        "print(f\"File hasil klasterisasi telah disimpan di {output_file}\")\n",
        "\n",
        "# Menyediakan file untuk di-download\n",
        "files.download(output_file)"
      ],
      "metadata": {
        "id": "mjAEYrsmqGK3"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}