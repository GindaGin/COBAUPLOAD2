{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YoybxMMjmFJl"
      },
      "outputs": [],
      "source": [
        "# Install library tambahan jika diperlukan\n",
        "!pip install scikit-fuzzy pandas scikit-learn matplotlib numpy\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "import numpy as np\n",
        "import skfuzzy as fuzz\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import files\n",
        "\n",
        "# Upload file CSV\n",
        "uploaded = files.upload()  # Pilih file CSV\n",
        "\n",
        "# Membaca data dari file CSV\n",
        "file_name = list(uploaded.keys())[0]\n",
        "data = pd.read_csv(file_name)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Pastikan kolom target tersedia\n",
        "target_columns = ['TSS', 'pH', 'EC', 'TDS', 'CHLA']\n",
        "data = data[target_columns]\n",
        "\n",
        "# Mengisi nilai NaN dengan median\n",
        "data = data.fillna(data.median())\n",
        "\n",
        "# Menstandarisasi data\n",
        "scaler = StandardScaler()\n",
        "scaled_data = scaler.fit_transform(data)\n",
        "\n",
        "\n",
        "# Fungsi untuk menghitung WL Index\n",
        "def calculate_wl_index(u, cntr, data_points):\n",
        "    numerator = 0\n",
        "    denominator = 0\n",
        "    num_clusters = len(cntr)\n",
        "\n",
        "    for i in range(num_clusters):\n",
        "        cluster_distances = np.linalg.norm(data_points - cntr[i], axis=1)**2\n",
        "        weighted_distances = np.sum((u[i] ** 2) * cluster_distances)\n",
        "        sum_membership = np.sum(u[i])\n",
        "        numerator += weighted_distances / sum_membership if sum_membership != 0 else 0\n",
        "\n",
        "    inter_cluster_distances = [np.linalg.norm(cntr[i] - cntr[j])**2 for i in range(num_clusters) for j in range(i + 1, num_clusters)]\n",
        "    if inter_cluster_distances:\n",
        "        min_distance = np.min(inter_cluster_distances)\n",
        "        median_distance = np.median(inter_cluster_distances)\n",
        "        denominator = min_distance + median_distance\n",
        "\n",
        "    return numerator / denominator if denominator != 0 else float('inf')\n",
        "\n",
        "# Fungsi untuk menghitung Fuzzy Silhouette Index\n",
        "def calculate_fsi(u, cntr, data_points, alpha=1):\n",
        "    \"\"\"\n",
        "    Menghitung Fuzzy Silhouette Index (FSI) berdasarkan rumus teoretis.\n",
        "\n",
        "    Parameters:\n",
        "    - u: matriks partisi fuzzy (shape: [n_cluster, n_data])\n",
        "    - cntr: array centroid (shape: [n_cluster, n_features])\n",
        "    - data_points: array data asli (shape: [n_data, n_features])\n",
        "    - alpha: parameter kontrol bobot (default = 1)\n",
        "\n",
        "    Returns:\n",
        "    - FSI (float)\n",
        "    \"\"\"\n",
        "    n_data = data_points.shape[0]\n",
        "    n_cluster = cntr.shape[0]\n",
        "    silhouette_scores = []\n",
        "    weights = []\n",
        "\n",
        "    for j in range(n_data):\n",
        "        # Hitung keanggotaan tertinggi dan kedua tertinggi\n",
        "        membership = u[:, j]\n",
        "        sorted_indices = np.argsort(membership)[::-1]  # descending\n",
        "        p = sorted_indices[0]\n",
        "        q = sorted_indices[1]\n",
        "\n",
        "        # Hitung a(i): jarak ke centroid klaster sendiri\n",
        "        a = np.linalg.norm(data_points[j] - cntr[p])\n",
        "\n",
        "        # Hitung b(i): jarak ke centroid klaster tetangga\n",
        "        b = np.linalg.norm(data_points[j] - cntr[q])\n",
        "\n",
        "        # Silhouette untuk titik j\n",
        "        if max(a, b) != 0:\n",
        "            s_j = (b - a) / max(a, b)\n",
        "        else:\n",
        "            s_j = 0\n",
        "\n",
        "        # Bobot berdasarkan beda keanggotaan\n",
        "        weight = (membership[p] - membership[q]) ** alpha\n",
        "\n",
        "        silhouette_scores.append(s_j * weight)\n",
        "        weights.append(weight)\n",
        "\n",
        "    fsi = np.sum(silhouette_scores) / np.sum(weights)\n",
        "    return fsi\n",
        "\n",
        "# Fuzzy C-Means\n",
        "for n_clusters in [2, 3, 4, 5]:\n",
        "    # Fuzzy C-Means clustering\n",
        "    cntr, u, _, _, _, _, _ = fuzz.cluster.cmeans(\n",
        "        scaled_data.T, n_clusters, 2, error=0.005, maxiter=1000, init=None\n",
        "    )\n",
        "    cluster_labels = np.argmax(u, axis=0)  # Klasterisasi berbasis derajat keanggotaan\n",
        "\n",
        "    # Simpan hasil klasterisasi\n",
        "    data[f'Cluster_{n_clusters}'] = cluster_labels\n",
        "\n",
        "    # Hitung jumlah data per klaster\n",
        "    print(f\"Jumlah data per klaster untuk {n_clusters} klaster:\")\n",
        "    for i in range(n_clusters):\n",
        "        cluster_size = np.sum(cluster_labels == i)\n",
        "        print(f\"  Cluster {i+1}: {cluster_size}\")\n",
        "\n",
        "    # Evaluasi Fuzzy C-Means\n",
        "    # Partition Coefficient (PC)\n",
        "    pc = np.mean(np.sum(u**2, axis=0))\n",
        "    # Partition Entropy (PE)\n",
        "    pe = -np.mean(np.sum(u * np.log(u), axis=0))\n",
        "    # Xie-Beni Index (XB)\n",
        "    min_dist = np.min([np.linalg.norm(cntr[i] - cntr[j]) for i in range(len(cntr)) for j in range(i + 1, len(cntr))])\n",
        "    distances = np.linalg.norm(scaled_data - cntr[:, None], axis=2)**2  # Menghitung jarak antar data dan pusat klaster\n",
        "    xb = np.sum(u * distances) / (len(data) * min_dist**2)\n",
        "    # WL Index (menggantikan MDI)\n",
        "    wl_index = calculate_wl_index(u, cntr, scaled_data)\n",
        "    # Fuzzy Silhouette Index (FSI)\n",
        "    fsi = calculate_fsi(u, cntr, scaled_data, alpha=1)\n",
        "\n",
        "    # Output evaluasi\n",
        "    print(f\"Evaluasi untuk {n_clusters} Klaster:\")\n",
        "    print(f\"  Partition Coefficient (PC): {pc:.4f}\")\n",
        "    print(f\"  Partition Entropy (PE): {pe:.4f}\")\n",
        "    print(f\"  Xie-Beni Index (XB): {xb:.4f}\")\n",
        "    print(f\"  WL Index: {wl_index:.4f}\")\n",
        "    print(f\"  Fuzzy Silhouette Index (FSI): {fsi:.4f}\")\n",
        "    print(\"-\" * 50)\n"
      ],
      "metadata": {
        "id": "904_ouC9wWA0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Contoh lihat keanggotaan fuzzy untuk 5 data pertama\n",
        "for i in range(5):\n",
        "    print(f\"Data ke-{i+1}: \", u[:, i])"
      ],
      "metadata": {
        "id": "uMvNXGIXbW65"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Simpan hasil ke CSV\n",
        "output_file = 'fcm_hasil_bobotsama.csv'\n",
        "data.to_csv(output_file, index=False)\n",
        "print(f\"Hasil klasterisasi disimpan di {output_file}.\")\n",
        "\n",
        "# mengunduh file CSV\n",
        "files.download(output_file)"
      ],
      "metadata": {
        "id": "lYpyCXvXqqjJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}