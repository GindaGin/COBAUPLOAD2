{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H97aLfuqF7jG"
      },
      "outputs": [],
      "source": [
        "# Install library tambahan jika diperlukan\n",
        "!pip install scikit-learn pandas matplotlib numpy dask\n",
        "\n",
        "# Import library\n",
        "import dask.dataframe as dd\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import silhouette_score, davies_bouldin_score, calinski_harabasz_score\n",
        "from sklearn.metrics import pairwise_distances\n",
        "\n",
        "# Upload file CSV\n",
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Membaca data dari file CSV menggunakan Dask\n",
        "file_name = list(uploaded.keys())[0]\n",
        "data = dd.read_csv(file_name)"
      ],
      "metadata": {
        "id": "S3p2Rr3RNckA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Target kolom yang akan digunakan\n",
        "target_columns = ['TSS', 'pH', 'EC', 'TDS', 'CHLA']\n",
        "data = data[target_columns]\n",
        "\n",
        "# Mengetahui jumlah nilai null per kolom\n",
        "null_counts = data.isna().sum().compute()\n",
        "print(\"Jumlah nilai null awal pada setiap kolom:\")\n",
        "print(null_counts)\n",
        "print(\"-\" * 50)\n",
        "\n",
        "# Mengisi nilai NaN dengan median (menggunakan Dask)\n",
        "data = data.fillna(data.median().compute())\n",
        "\n",
        "# Memastikan tidak ada nilai null setelah pengisian\n",
        "null_counts_after = data.isna().sum().compute()\n",
        "print(\"Jumlah nilai null setelah pengisian:\")\n",
        "print(null_counts_after)\n",
        "print(\"-\" * 50)\n",
        "\n",
        "# Mengonversi ke Pandas untuk kompatibilitas dengan Scikit-learn\n",
        "data = data.compute()\n",
        "\n",
        "# Standarisasi data\n",
        "scaler = StandardScaler()\n",
        "scaled_data = scaler.fit_transform(data)"
      ],
      "metadata": {
        "id": "Iu4IgiGiNfcd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.cluster import KMeans\n",
        "import numpy as np\n",
        "\n",
        "def gap_statistic(X, n_refs=10, n_clusters=5):\n",
        "    shape = X.shape\n",
        "    tops = X.max(axis=0)\n",
        "    bottoms = X.min(axis=0)\n",
        "    dists = np.diag(tops - bottoms)\n",
        "\n",
        "    # Generate n_refs acak dataset dalam bounding box data asli\n",
        "    random_wss = []\n",
        "    for _ in range(n_refs):\n",
        "        random_data = np.random.random_sample(size=shape)\n",
        "        random_data = random_data @ dists + bottoms\n",
        "        kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)\n",
        "        kmeans.fit(random_data)\n",
        "        random_wss.append(kmeans.inertia_)\n",
        "\n",
        "    # Hitung WSS data asli\n",
        "    kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)\n",
        "    kmeans.fit(X)\n",
        "    original_wss = kmeans.inertia_\n",
        "\n",
        "    # Gap Statistic\n",
        "    log_wss_random = np.log(random_wss)\n",
        "    gap = np.mean(log_wss_random) - np.log(original_wss)\n",
        "\n",
        "    return gap\n",
        "\n",
        "for n_clusters in [2, 3, 4, 5]:\n",
        "    kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)\n",
        "    data['Cluster'] = kmeans.fit_predict(scaled_data)\n",
        "\n",
        "    silhouette_avg = silhouette_score(scaled_data, data['Cluster'])\n",
        "    dbi = davies_bouldin_score(scaled_data, data['Cluster'])\n",
        "    calinski_harabasz = calinski_harabasz_score(scaled_data, data['Cluster'])\n",
        "    wss = kmeans.inertia_\n",
        "    gap = gap_statistic(scaled_data, n_refs=10, n_clusters=n_clusters)\n",
        "\n",
        "    print(f\"Evaluasi untuk {n_clusters} Klaster:\")\n",
        "    print(f\"  Davies-Bouldin Index: {dbi:.5f}\")\n",
        "    print(f\"  Silhouette Score: {silhouette_avg:.5f}\")\n",
        "    print(f\"  Calinski-Harabasz Index: {calinski_harabasz:.5f}\")\n",
        "    print(f\"  Within-Cluster Sum of Squares (WSS / Cohesion): {wss:.5f}\")\n",
        "    print(f\"  Gap Statistic: {gap:.5f}\")\n",
        "    print(\"-\" * 50)\n"
      ],
      "metadata": {
        "id": "cV_XrcJdNT0-",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import silhouette_score, davies_bouldin_score, calinski_harabasz_score\n",
        "from sklearn.metrics import pairwise_distances\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "for n_clusters in [2, 3, 4, 5]:\n",
        "    kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
        "    data['Cluster'] = kmeans.fit_predict(equal_weighted_data)\n",
        "\n",
        "    # Menampilkan jumlah data dalam setiap klaster\n",
        "    cluster_counts = data['Cluster'].value_counts().sort_index()\n",
        "    print(f\"\\nJumlah data per klaster untuk {n_clusters} Klaster:\")\n",
        "    for cluster, count in cluster_counts.items():\n",
        "        print(f\"  Cluster {cluster + 1}: {count}\")\n",
        "\n",
        "    print(\"-\" * 50)"
      ],
      "metadata": {
        "id": "Soq5Zwo-0FGS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Klasterisasi menggunakan KMeans dengan 5 klaster\n",
        "kmeans = KMeans(n_clusters=5, random_state=42)\n",
        "kmeans.fit(scaled_data)\n",
        "data['Cluster'] = kmeans.labels_\n",
        "\n",
        "# Step 3: Hitung rata-rata tiap variabel per klaster\n",
        "cluster_means = pd.DataFrame(scaled_data, columns=target_columns)\n",
        "cluster_means['Cluster'] = kmeans.labels_\n",
        "cluster_means = cluster_means.groupby('Cluster').mean()\n",
        "\n",
        "print(\"Rata-rata tiap variabel setelah standarisasi per klaster:\")\n",
        "print(cluster_means)\n",
        "\n",
        "# Step 4: Membuat radar plot per klaster\n",
        "def create_spider_plot_per_cluster(cluster_means):\n",
        "    labels = cluster_means.columns.tolist()\n",
        "    num_vars = len(labels)\n",
        "    angles = np.linspace(0, 2 * np.pi, num_vars, endpoint=False).tolist()\n",
        "    angles += angles[:1]\n",
        "\n",
        "    # Warna untuk 5 klaster\n",
        "    colors = ['#1f77b4', 'orange', 'green', 'red', 'purple']\n",
        "\n",
        "    for cluster in cluster_means.index:\n",
        "        values = cluster_means.loc[cluster].values.flatten().tolist()\n",
        "        values += values[:1]\n",
        "\n",
        "        fig, ax = plt.subplots(figsize=(7, 7), subplot_kw=dict(polar=True))\n",
        "        ax.plot(angles, values, marker='o', linewidth=2, color=colors[cluster])\n",
        "        ax.fill(angles, values, alpha=0.25, color=colors[cluster])\n",
        "\n",
        "        ax.set_xticks(angles[:-1])\n",
        "        ax.set_xticklabels(labels, fontsize=10, rotation=30, ha=\"right\")\n",
        "\n",
        "        ax.set_title(f'Radar Plot Klaster {cluster+1}', size=14, y=1.08)\n",
        "        ax.set_yticklabels([])\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "# Panggil fungsi untuk buat radar per klaster\n",
        "create_spider_plot_per_cluster(cluster_means)\n"
      ],
      "metadata": {
        "id": "grl_39tm1gUw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_combined_spider_plot(cluster_means):\n",
        "    labels = cluster_means.columns.tolist()\n",
        "    num_vars = len(labels)\n",
        "    angles = np.linspace(0, 2 * np.pi, num_vars, endpoint=False).tolist()\n",
        "    angles += angles[:1]\n",
        "\n",
        "    # Warna untuk 5 klaster\n",
        "    colors = ['#1f77b4', 'orange', 'green', 'red', 'purple']\n",
        "\n",
        "    # Buat figure tunggal\n",
        "    fig, ax = plt.subplots(figsize=(8, 8), subplot_kw=dict(polar=True))\n",
        "\n",
        "    for cluster in cluster_means.index:\n",
        "        values = cluster_means.loc[cluster].values.flatten().tolist()\n",
        "        values += values[:1]\n",
        "\n",
        "        ax.plot(angles, values, marker='o', linewidth=2, label=f'Klaster {cluster+1}', color=colors[cluster])\n",
        "        ax.fill(angles, values, alpha=0.15, color=colors[cluster])\n",
        "\n",
        "    ax.set_xticks(angles[:-1])\n",
        "    ax.set_xticklabels(labels, fontsize=10, rotation=30, ha=\"right\")\n",
        "\n",
        "    ax.set_title('Radar Plot Tiap Klaster', size=16, y=1.1)\n",
        "    ax.set_yticklabels([])\n",
        "\n",
        "    ax.legend(loc='upper right', bbox_to_anchor=(1.3, 1.1))\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Panggil fungsi\n",
        "create_combined_spider_plot(cluster_means)\n"
      ],
      "metadata": {
        "id": "P4NE-8mA14qt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Menambahkan kolom 'Cluster_X' untuk setiap jumlah klaster\n",
        "for n_clusters in [2, 3, 4, 5]:\n",
        "    kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
        "    data[f'Cluster_{n_clusters}'] = kmeans.fit_predict(equal_weighted_data)\n",
        "\n",
        "# Mengekspor data ke file Excel\n",
        "output_file = 'hasil_klasterisasi_kmeans_bobotsama_revisi1.xlsx'\n",
        "data.to_excel(output_file, index=False)\n",
        "\n",
        "# Memberi tahu pengguna bahwa file telah disimpan\n",
        "print(f\"File hasil klasterisasi telah disimpan di {output_file}\")"
      ],
      "metadata": {
        "id": "1cDS99lS1uMT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Menyediakan file untuk di-download\n",
        "files.download(output_file)"
      ],
      "metadata": {
        "id": "1JTkeZQL2GTj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}